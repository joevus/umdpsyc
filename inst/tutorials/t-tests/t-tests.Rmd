---
title: "T-tests"
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
tutorial:
  id: "t-tests"
  version: 0.5
---


```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(umdpsyc)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(exercise.checker = gradethis::grade_learnr)
learnr::tutorial_options(
  exercise.timelimit = 60)

```

## Hypothesis Tests

```{r}
data("exam_scores")
```

The steps to a hypothesis are:

1) State your hypotheses.

2) Set the criterion.

3) Collect sample data.

4) Calculate the test statistic.

5) Evaluate and interpret.

Most of these steps will be done outside of R, and in fact, they can generally only be done outside of R. However, R can be very useful for the computational part, step 4. 

In this tutorial, we will use R to calculate the test statistic as part of performing a t-test.

## Hypothesis Test Setup

$$H_0: \mu = 80 $$
$$H_A: \mu \ne 80$$


## Using `t.test()`

We can do the t-test by hand by calculating the test statistic and finding the critical value, but `R` also has a convenient way of doing it using just the data with the `t.test` function. You do need to make sure you still go through all of the steps of performing a hypothesis test though --  the `t.test()` function will perform the test for you, but you need to make sure to provide all of the appropriate arguments.

Let's look at doing a simple two-sided test, with a null hypothesis that $\mu = 12000$. We provide the vector of data points, as well as an argument providing the null value. In this case, since the value is in thousands, we use `mu = 80`. 

```{r, echo = TRUE}
t.test(exam_scores$exam1, mu = 80)
```

By default, this does a two-sided test. What if we wanted to do a one-sided test? We can use the `alternative` argument to change it.

```{r, echo = TRUE}
# These are how to do one-sided tests.
# Note: This is just to show that it's possible! Don't 
# change the sidedness after the fact like this!
t.test(exam_scores$exam1, mu = 80, alternative = "greater")
t.test(exam_scores$exam1, mu = 80, alternative = "less")
```

Note that this doesn't provide the conclusion of the test for you. You need to make the correct conclusion from these results. Basically, you just need to take the p-value and compare it to the alpha level like before. 

Lastly, notice that the output gives you information about the confidence interval. You can use the `t.test()` function to create confidence intervals as well. Just make sure you use the `conf.level` argument to specify the type of confidence interval you want.

```{r, echo = TRUE}
t.test(mtcars$mpg, conf.level = 0.99)
```

If you're just making a confidence interval, you can ignore the rest of the information. Here, I ran `t.test()` without anything for `mu` -- this gave me a test comparing it to 0, but I don't need that information since all I need is the confidence interval. 

## Two Sample t-tests

### Independent Samples t-test

Doing an independent samples t-test can be done one of two ways. If you have the data from the two samples in two vectors, you can simply use those vectors to run the t-test. In a data frame, this would mean that the two samples are stored as two separate columns. 

If we wanted to run a t-test to see if there was as signficant difference between exam 1 and exam 2, then we could use the following code.

```{r, echo = TRUE}
t.test(exam_scores$exam1, exam_scores$exam2)
```

###

What if the data were stored in a way such that all the values were in one column, with the corresponding groups in another column? That is, for example, what if we wanted to do an independent samples t-test for exams scores of students who took notes by paper compared to students who took notes by computer?

We can use formula notation in this case.

```{r, echo = TRUE}
t.test(exam1 ~ note_mode, data = exam_scores)
```

On the left of the tilde (`~`), we have the numerical variable that we want to use the mean of. On the right side, we put the categorical variable that denotes which person is in which group. The `data = exam_scores` argument, as before, denotes which data to pull these columns from. 

### Paired t-test

Above, we used an independent sample t-test to look at the difference between exam 1 and exam 2 scores. This isn't quite how we should approach this, though. Remember, each student took both exams, so this is actually a paired t-test, since the scores on each exam are paired according to which student took them. We can do a paired t-test by adding an argument `paired = TRUE` to the `t.test` function.

```{r, echo = TRUE}
t.test(exam_scores$exam1, exam_scores$exam2, paired = TRUE)
```

## Exercises

### Exercise 1

Consider the `exam_scores` data that is included in the `umdpsyc` package. 

```{r exercises-setup}
data(exam_scores)
```

```{r exercise1-structure, echo = TRUE, exercise = TRUE}
str(exam_scores)
```

Suppose you are interested in whether there is a relationship between the method of note-taking and the score on exam 1. That is, in words, your null hypothesis is that the mean score on exam 1 for students who took notes by paper is the same as the mean score on exam 1 for students who took notes by computer. Your alternative hypothesis is that they are not the same. You use a two-sided test, and set an alpha level of 0.05. 

How would you run the test in R?

```{r exercise1, echo = TRUE, exercise = TRUE}

```


```{r exercise1-check}
grade_result(
  pass_if(~ identical(.result, t.test(exam1 ~ note_mode, data = exam_scores)), "Good job!"),
  fail_if(~ TRUE, "Not quite. Try again.")
)

```
### Exercise 2



```{r exercise2, echo = TRUE, exercise = TRUE}

```

### Exercise 3

How would you subset the dataset to only include people who took notes by paper? 

```{r exercise3, echo = TRUE, exercise = TRUE}

```

```{r exercise3-check}
grade_result(
  pass_if(~ identical(.result, exam_scores[exam_scores$note_mode == 1,]), "Good job!"),
  fail_if(~ TRUE, "Not quite. Try again.")
)

```

### Exercise 4

```{r exercise4}
learnr::question("What would be the conclusion from this hypothesis test?",
         answer("Fail to reject the null hypothesis.", correct=FALSE),
         answer("Reject the null hypothesis.", correct = TRUE,  message = "Good job!"),
         allow_retry = TRUE,
         random_answer_order = TRUE
)
```

### Submitting work

```{r submission-setup}
submission_code <- function(UID, exercise = 'data-frames'){
  httr::sha1_hash('ttest123',as.character(UID))
}
```

Generate your submission code by putting in your UID in the function below. For example, if your UID is `2`, then your code should look like `submission_code(UID = 2)`
```{r submission, exercise = TRUE}
submission_code(UID = )
```
